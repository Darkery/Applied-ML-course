{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning\n",
    "## Inference\n",
    "- Author: Lorien Pratt\n",
    "- Copyright: Quantellia LLC 2019.  All Rights Reserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs machine learning inference on an already-trained model, using data obtained from interactive front-end widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the interact library, which is used to create interactive widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Label, HBox, SliderStyle\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable integration between Python and R using the [__`RPy2`__](https://rpy2.readthedocs.io/en/version_2.8.x/) python package developed by Laurent Gautier and the rest of the rpy2 team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.rinterface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jing'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R my_initials<-\"jing\" # Set my initials to use for model and data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up R and H2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only needed the first time you run on this server\n",
    "#%%R\n",
    "#install.packages(\"h2o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Loading required package: h2o\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Your next step is to start H2O:\n",
      "    > h2o.init()\n",
      "\n",
      "For H2O package documentation, ask for help:\n",
      "    > ??h2o\n",
      "\n",
      "After starting H2O, you can use the Web UI at http://localhost:54321\n",
      "For more information visit http://docs.h2o.ai\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: \n",
      "Attaching package: ‘h2o’\n",
      "\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    cor, sd, var\n",
      "\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    &&, %*%, %in%, ||, apply, as.factor, as.numeric, colnames,\n",
      "    colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n",
      "    log10, log1p, log2, round, signif, trunc\n",
      "\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R require(h2o) #Note this will generate warnings, but these are really informational, not warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the R model inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%R\n",
    "## stub function for testing\n",
    "## This version of the MLmodel uses a vector of inputs instead of individual arguments\n",
    "#MLmodelV<-function(a){return(a[1] + a[2])} \n",
    "#MLmodelV(c(3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "H2O is not running yet, starting it now...\n",
       "\n",
       "Note:  In case of errors look at the following log files:\n",
       "    /tmp/RtmpTx4gKx/h2o_jupyter_started_from_r.out\n",
       "    /tmp/RtmpTx4gKx/h2o_jupyter_started_from_r.err\n",
       "\n",
       "\n",
       "Starting H2O JVM and connecting: . Connection successful!\n",
       "\n",
       "R is connected to the H2O cluster: \n",
       "    H2O cluster uptime:         2 seconds 818 milliseconds \n",
       "    H2O cluster timezone:       Etc/UTC \n",
       "    H2O data parsing timezone:  UTC \n",
       "    H2O cluster version:        3.26.0.10 \n",
       "    H2O cluster version age:    5 days  \n",
       "    H2O cluster name:           H2O_started_from_R_jupyter_mcy252 \n",
       "    H2O cluster total nodes:    1 \n",
       "    H2O cluster total memory:   0.39 GB \n",
       "    H2O cluster total cores:    1 \n",
       "    H2O cluster allowed cores:  1 \n",
       "    H2O cluster healthy:        TRUE \n",
       "    H2O Connection ip:          localhost \n",
       "    H2O Connection port:        54321 \n",
       "    H2O Connection proxy:       NA \n",
       "    H2O Internal Security:      FALSE \n",
       "    H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4 \n",
       "    R Version:                  R version 3.6.1 (2019-07-05) \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note this will generate several messages; they are not errors\n",
    "%R h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the model file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Make name of model file from my initials\n",
    "# Note that loadModel requires you specify the model name, which is the file within the directory\n",
    "# that was created during saveModel. This is weird.\n",
    "model_filename<-paste0(\"models/\",my_initials,\"_auto_model/model_1\")\n",
    "model=h2o.loadModel(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the ModelV function so that it puts the input data into a dataframe and converts that to _hex, which is what's needed to use the model to do a prediction (inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "MLmodelV<-function(a){\n",
    "    # Convert to a data frame, needed for conversion to hex, needed to\n",
    "    # do predictions\n",
    "    # transpose (t) is so that we get one row instead of one column in the df\n",
    "    test_data_df<-data.frame(t(matrix(a)))\n",
    "    # Make the column names in this data frame the same as the training data names.  The model\n",
    "    # object kindly stores these for us (see str(model) to inspect this)\n",
    "    names(test_data_df)<- model@parameters$x\n",
    "    # Convert from a data frame to the hex format needed for h2o prediction\n",
    "    # the capture.output wrapper is to suppress the progress bars that h2o normally generates\n",
    "    capture.output(test_data_hex<-as.h2o(test_data_df,quite_mode=TRUE),file=\"NUL\")\n",
    "    # Run machine learning inference: what does this model predict for this data?\n",
    "    capture.output(result <-h2o.predict(model, test_data_hex),file=\"NUL\") \n",
    "    return(as.numeric(result[1,1]))\n",
    "}\n",
    "\n",
    "# Testing code:\n",
    "#str(model@parameters$x)\n",
    "#model@parameters$x\n",
    "##actual_column <- as.logical(as.vector(as.numeric(test_hex[ ,ncol(test_hex)])))\n",
    "#actual_column <- as.vector(as.numeric(test_hex[targetcol]))\n",
    "#predict_column <- as.vector(predictions[ ,'predict'])\n",
    "#MLmodelV<-function(a){\n",
    "#    return(a[1] + a[2])} \n",
    "#MLmodelV(c(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only for testing\n",
    "# Make a test data set to send to the model file, so we don't have to test with the UI\n",
    "#test_data=[1,2,3,4,5,6,7]\n",
    "#%Rpush test_data\n",
    "#%R result<-MLmodelV(test_data);\n",
    "#%R -o result \n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only for testing\n",
    "#%%R\n",
    "#x<-h2o.predict(model, test_data_hex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the python function that interfaces to R; it also vectorizes the input values and prints the mpg result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mpg:  [ 32.50120676]\n"
     ]
    }
   ],
   "source": [
    "def f2(a,b,c,d,e,f,g):\n",
    "    q=[a,b,c,d,e,f,g] # Create a vector from the individual arguments before sending to R\n",
    "    %Rpush q\n",
    "    %%R result<-MLmodelV(q);\n",
    "    %R -o result \n",
    "    print('Estimated mpg: ', result)\n",
    "f2(1,2,4,5,6,7,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the UI to accesss the ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create styles to be used for the layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up descripton fields to not be truncated\n",
    "# See http://www.blog.pythonlibrary.org/2018/10/24/working-with-jupyter-notebook-widgets/\n",
    "style = {'description_width': 'initial'}\n",
    "style = {'description_width': '300px'} # width of the box for the descriptoin\n",
    "layout=widgets.Layout(width='600px')   # Size of the entire box for the widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create widgets (title and sliders) for the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the result of analyzing each field to see what its range is. We'll use this to determine\n",
    "# what the right range for inference sliders is\n",
    "#print(summary(auto$cylinders)) # we'll call this 3-8 on an integer range\n",
    "#print(summary(auto$displacement)) # we'll call this 0 - 500 on an integer range\n",
    "#print(summary(auto$horsepower)) # we'll call this 0 - 500 on an integer range\n",
    "#print(summary(auto$weight)) # we'll call this 1000 - 10000 on an integer range\n",
    "#print(summary(auto$acceleration)) # we'll call this 0-100 on a float range\n",
    "#print(summary(auto$model.year)) # we'll call this 60-90 on an integer range\n",
    "#print(summary(auto$origin)) # we'll call this 1,2,3 on an integer range\n",
    "auto_title_widget=widgets.HTML('<h2>Use a machine learning model to estimate car miles per gallon (MPG)</h2>',layout=layout)\n",
    "auto_cylinders_widget=widgets.IntSlider(min=3,max=8, description='cylinders',style=style, \n",
    "                                        layout=layout)\n",
    "auto_displacement_widget=widgets.IntSlider(min=0,max=500,description='engine displacement (cu inches)',style=style,\n",
    "                                          layout=layout)\n",
    "auto_horsepower_widget=widgets.IntSlider(min=0,max=500,description='horsepower',style=style,\n",
    "                                          layout=layout)\n",
    "auto_weight_widget=widgets.IntSlider(min=1000,max=10000,description='weight (in pounds)',style=style,\n",
    "                                          layout=layout)\n",
    "auto_acceleration_widget=widgets.FloatSlider(min=0,max=100,description='acceleration (time (sec) from 0-60)',style=style,\n",
    "                                          layout=layout)\n",
    "auto_modelyear_widget=widgets.IntSlider(min=60,max=90,description='model year',style=style,\n",
    "                                          layout=layout)\n",
    "auto_origin_widget=widgets.IntSlider(min=1,max=3,description='origin (1=american, 2=european, 3=japanese)',style=style,\n",
    "                                          layout=layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assemble the widgets into a UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of widgets to be passed to the UI below\n",
    "widget_list = [ auto_title_widget,\n",
    "                   auto_cylinders_widget,\n",
    "                   auto_displacement_widget,\n",
    "                   auto_horsepower_widget,\n",
    "                   auto_weight_widget,\n",
    "                   auto_acceleration_widget,\n",
    "                   auto_modelyear_widget,\n",
    "                   auto_origin_widget\n",
    "                  ]\n",
    "\n",
    "# Organize the widgets into a box\n",
    "# Make a bit bigger layout than the widgets to avoid a horizontal scroll bar\n",
    "ui = widgets.GridBox( widget_list,layout=widgets.Layout(width='800px') ) \n",
    "\n",
    "out = widgets.interactive_output(f2, {'a': auto_cylinders_widget, \n",
    "                                      'b': auto_displacement_widget,\n",
    "                                      'c': auto_horsepower_widget,\n",
    "                                      'd': auto_weight_widget,\n",
    "                                      'e': auto_acceleration_widget,\n",
    "                                      'f': auto_modelyear_widget,\n",
    "                                      'g': auto_origin_widget\n",
    "                                     })\n",
    "# Other arguments I might think about using for the grid box\n",
    "#widgets.GridBox(items, layout=widgets.Layout(grid_template_columns=\"repeat(3, 100px)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn off progress bars in H2o, so they won't show up during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "h2o.no_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the UI, which combines all of the above elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e149680708463d9323e0e2f59f7d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "R3JpZEJveChjaGlsZHJlbj0oSFRNTCh2YWx1ZT11JzxoMj5Vc2UgYSBtYWNoaW5lIGxlYXJuaW5nIG1vZGVsIHRvIGVzdGltYXRlIGNhciBtaWxlcyBwZXIgZ2FsbG9uIChNUEcpPC9oMj4nLCDigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5fc4c0a30444419571896d933f6aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "T3V0cHV0KG91dHB1dHM9KHt1J291dHB1dF90eXBlJzogdSdzdHJlYW0nLCB1J25hbWUnOiB1J3N0ZG91dCcsIHUndGV4dCc6IHUnRXN0aW1hdGVkIG1wZzogIFsgMzEuNTY5NjkwNDFdXG4nfSzigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ui, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
